from cgi import test
from tkinter.messagebox import NO
import numpy as np
from sklearn import preprocessing
import random
from refer import Property
import math
# from Lost_Action import Agent_actions
import pandas as pd

class Agent():

    def __init__(self, env, marking_param, *arg):
        self.env = env
        self.actions = env.actions
        self.GOAL_REACH_EXP_VALUE = 50 # max_theta # 50
        self.lost = False
        self.test = False
        self.grid = arg[0]
        self.map = arg[1]
        self.NODELIST = arg[2]
        self.refer = Property()
        self.marking_param = marking_param
        "======================================================="
        # self.decision_action = Agent_actions(self.env)
        "======================================================="
        self.Node_l = ["s", "A", "B", "C", "D", "E", "F", "O", "g", "x"]

    def policy_advance(self, state, TRIGAR, action):
        
        self.TRIGAR_advance = TRIGAR
        self.prev_action = action
        # print("Prev Action : {}".format(action))

        action = self.model_advance(state)
        self.Advance_action = action

        print("Action : {}".format(action))
        # print("Advance action : {}".format(self.Advance_action))

        if action == None:
            print("ERROR ğŸ¤–")
            return self.prev_action, self.Reverse, self.TRIGAR_advance # ã“ã®prev action ã‚‚ä»®
            
        return action, self.Reverse, self.TRIGAR_advance

    def mdp(self, state, TRIGAR, action,     states_known, map, grid, DIR):
        self.TRIGAR_advance = TRIGAR

        y_n = False
        self.All = False
        self.Reverse = False

        # if self.NODELIST[state.row][state.column] == "x":
        #     self.TRIGAR_advance = False
        
        # from mdp_virtual import ValueIterationPlanner
        from mdp_MP import ValueIterationPlanner

        
        test = ValueIterationPlanner(self.env)

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        y_n = False
        # bp = False
        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()
        # ä»Šã¯ã“ã“ã«å…¥ã£ã¦bp_algorithmã«é·ç§»ã—ã¦ã„ã‚‹
        if self.NODELIST[state.row][state.column] in pre:
                print("========\næ¢ç´¢çµ‚äº†\n========")
                self.trigar = False
                # bp = True
        elif self.NODELIST[state.row][state.column] == "x":
            print("========\näº¤å·®ç‚¹\n========")
            self.trigar = False
            self.TRIGAR_advance = False
        else:
            self.trigar = None
        print("========\næ¢ç´¢é–‹å§‹\n========")
        exp_action = []
        for dir in next_diretion:
            # print("dir:{}".format(dir))
            y_n, action = self.env.expected_move(state, dir, self.trigar, self.All, self.marking_param)
            if y_n:
                y_n = False
                exp_action.append(action)
                # print("===== adv action : {} =====".format(exp_action))

        # pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        if self.NODELIST[state.row][state.column] in pre or self.NODELIST[state.row][state.column] == "x":

            # import pprint
            # from env_virtual import State
            # size = 19 # 3
            # import copy
            # # pprint.pprint(states_known)
            # state_init = copy.copy(state)
            # # state_init = State(1, 1) # ä»®æƒ³åº§æ¨™
            # m = [[1.0 for i in range(size)] for i in range(size)] #known or unknown
            # for i in range(-1,2):
            #     if state_init.row+i < 0 or state_init.row+i >=size:
            #         continue
            #     for j in range(-1,2):
            #         if state_init.column+j < 0 or state_init.column+j >=size:
            #             continue
                    
            #         m[state_init.row+i][state_init.column+j] = 0
            # size = 19
            size = self.env.row_length
            m = [[1.0 for i in range(size)] for i in range(size)] #known or unknown
            for i in range(-1,2):
                if state.row+i < 0 or state.row+i >=size:
                    continue
                for j in range(-1,2):
                    if state.column+j < 0 or state.column+j >=size:
                        continue
                    
                    m[state.row+i][state.column+j] = 0
            states_known = set() #empty set
            for s in self.env.states:
                    if m[s.row][s.column] == 0:
                        states_known.add(s)

            # ns1 = copy.copy(state_init) # state.self.St.clone
            # ns2 = copy.copy(state_init) # state.self.St.clone
            # ns3 = copy.copy(state_init) # state.self.St.clone
            # ns4 = copy.copy(state_init) # state.self.St.clone
            # "å‰å¾Œå·¦å³ã®ãƒã‚¹ -> ä»Šã¯å¯è¦–åŒ–ã®ãŸã‚ã«åº§æ¨™ç³»ã‚’å‡ºã—ã¦ã„ã‚‹ãŒstate=(0, 0)"
            # states_known2 = set()
            # states_known2.add(state_init)
            # ns1.row -= 1
            # states_known2.add(ns1)
            # ns2.row += 1
            # states_known2.add(ns2)
            # ns3.column -= 1
            # states_known2.add(ns3)
            # ns4.column += 1
            # states_known2.add(ns4)

            # states_known2.add(State(0, 2))
            # states_known2.add(State(2, 2))
            # states_known2.add(State(0, 0))
            # states_known2.add(State(2, 0))

            # states_known2 = set()
            # states_known2.add(State(0, 0))
            # ns1.row -= 1
            # states_known2.add(ns1)
            # states_known2.add(State(0, 2))
            # ns3.column -= 1
            # states_known2.add(ns3)
            # states_known2.add(state_init)
            # ns4.column += 1
            # states_known2.add(ns4)
            # states_known2.add(State(2, 0))
            # ns2.row += 1
            # states_known2.add(ns2)
            # states_known2.add(State(2, 2))
            # print("----- states known 2 -----")
            # pprint.pprint(states_known2)

            
            print("Unexplore:", exp_action)
            if not exp_action:
                self.TRIGAR_advance = True
                exp_action = next_diretion # å…¨æ–¹å‘æ¢ç´¢ã—ãŸå ´åˆã¯é¸æŠæ–¹å‘ã‚’åˆæœŸåŒ–ã™ã‚‹

            # a, v, aaa = test.plan(states_known, map, state, DIR, exp_action) # here
            a, v, aaa = test.plan(states_known, m, state, DIR, exp_action) # here
            # a, v, aaa = test.plan(states_known2, m, state_init, DIR,     exp_action)
            
            new_pi = (aaa[state]) # here
            
            # new_pi = (aaa[state_init])

            
            print("===== NEW PI =====\n", new_pi)
            action = new_pi
            # test.show(aaa, v, state_init, m, DIR)
            test.show(aaa, v, state, m, DIR)
            test.show_values(a)

            
            # self.env.mark(state, None)
        
        else:
            "é€²ã‚ã‚‹æ–¹å‘ã«ç¶™ç¶šã—ã¦é€²ã‚€"
            if not exp_action:
                self.TRIGAR_advance = True
            else:
                print(f"----- {exp_action} -----")
                action = exp_action[0]
                print("===== NEW PI =====\n", action)

        
            
        return action, self.Reverse, self.TRIGAR_advance

    def policy_bp(self, state, TRIGAR, TRIGAR_REVERSE, COUNT):
        self.TRIGAR_bp = TRIGAR
        self.TRIGAR_REVERSE_bp = TRIGAR_REVERSE
        self.All = False
        self.Reverse = False
        self.COUNT = COUNT

        try:
            action, self.Reverse = self.model_bp(state)
            print("Action : {}".format(action))
        except:
        # except Exception as e:
        #     print('=== ã‚¨ãƒ©ãƒ¼å†…å®¹ ===')
        #     print('type:' + str(type(e)))
        #     print('args:' + str(e.args))
        #     print('message:' + e.message)
        #     print('eè‡ªèº«:' + str(e))
            print("agent / policy_bp ERROR")

            "å‹•ã„ã¦ã„ãªã„æ™‚ã«è¿·ã£ãŸã¨ã™ã‚‹å ´åˆ"
            # if NOT_MOVE:
            #     self.All = True
            
            # ã“ã‚Œã®ãŠã‹ã’ã§æ²¼ã§ã‚‚å°‘ã—å‹•ã‘ã¦ã„ã‚‹
            return random.choice(self.actions), self.Reverse, self.lost
            
        return action, self.Reverse , self.lost

    def policy_exp(self, state, TRIGAR):
        self.trigar = TRIGAR
        attribute = self.NODELIST[state.row][state.column]
        next_direction = random.choice(self.actions)
        self.All = False
        bp = False
        self.lost = False
        self.Reverse = False
        
        try:
            y_n, action, bp = self.model_exp(state)
            print("y/n:{}".format(y_n))
            print("Action : {}".format(action))
        except:
            print("ã“ã®ãƒãƒ¼ãƒ‰ã‹ã‚‰æ¢ç´¢ã§ãã‚‹è¨±å®¹ç¯„å›²ã¯æ¢ç´¢æ¸ˆã¿\næˆ»ã‚‹å ´æ‰€æ±ºå®šã®ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ã¸")
            print("TRIGAR : {}".format(self.trigar))
            # self.All = True
            return self.actions[1], bp, self.All, self.trigar, self.Reverse, self.lost
        return action, bp, self.All, self.trigar, self.Reverse, self.lost

    def model_exp(self, state, TRIGAR):
        self.trigar = TRIGAR
        # attribute = self.NODELIST[state.row][state.column]
        # next_direction = random.choice(self.actions)
        # self.All = False
        # bp = False
        # self.lost = False
        # self.Reverse = False

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]

        y_n = False
        bp = False
        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        # ä»Šã¯ã“ã“ã«å…¥ã£ã¦bp_algorithmã«é·ç§»ã—ã¦ã„ã‚‹
        if self.NODELIST[state.row][state.column] in pre:
                print("========\næ¢ç´¢çµ‚äº†\n========")
                self.trigar = False
                bp = True
        elif self.NODELIST[state.row][state.column] == "x":
            print("========\näº¤å·®ç‚¹\n========")
            self.trigar = False

        print("========\næ¢ç´¢é–‹å§‹\n========")

        exp_action = []
        for dir in next_diretion:

            print("dir:{}".format(dir))
            y_n, action = self.env.expected_move(state, dir, self.trigar, self.All, self.marking_param)
            
            if y_n:
                y_n = False
                exp_action.append(action)
                # print("===== exp action : {} =====".format(exp_action))

        if exp_action:
            
            # if self.NODELIST[state.row][state.column] in pre: # "x":
            "Edit"
            if self.NODELIST[state.row][state.column] in pre or self.NODELIST[state.row][state.column] == "x": # here
                print("========\näº¤å·®ç‚¹\n========")
                ##############
                Average_Value = self.decision_action.value(exp_action)
                ##############
                print("\n===================\nğŸ¤–âš¡ï¸ Average_Value:{}".format(Average_Value))
                print(" == å„è¡Œå‹•å¾Œã«ã‚¹ãƒˆãƒ¬ã‚¹ãŒæ¸›ã‚‰ã›ã‚‹ç¢ºç‡:{}".format(Average_Value))
                print(" == ã¤ã¾ã‚Šã€æ–°ã—ã„æƒ…å ±ãŒå¾—ã‚‰ã‚Œã‚‹ç¢ºç‡:{} -----> ã“ã‚ŒãŒä¸€ç•ªé‡è¦ãƒ»ãƒ»ãƒ»æœªæ¢ç´¢ã‹ã¤ã“ã®æ•°å€¤ãŒå¤§ãã„æ–¹å‘ã®è¡Œå‹•ã‚’é¸æŠ\n===================\n".format(Average_Value))
                ##############
                action_value = self.decision_action.policy(Average_Value)
                ##############
                if action_value == self.env.actions[2]: #  LEFT:
                    NEXT = "LEFT  â¬…ï¸"
                    print("    At :-> {}".format(NEXT))
                if action_value == self.env.actions[3]: # RIGHT:
                    NEXT = "RIGHT â¡ï¸"
                    print("    At :-> {}".format(NEXT))  
                if action_value == self.env.actions[0]: #  UP:
                    NEXT = "UP    â¬†ï¸"
                    print("    At :-> {}".format(NEXT))
                if action_value == self.env.actions[1]: # DOWN:
                    NEXT = "DOWN  â¬‡ï¸"
                    print("    At :-> {}".format(NEXT))

                print("éå»ã®ã‚¨ãƒ”ã‚½ãƒ¼ãƒ‰ã‹ã‚‰ã€ç¾æ™‚ç‚¹ã§ã¯ã€ğŸ¤–âš ï¸ At == {}ã‚’é¸æŠã™ã‚‹".format(action_value))
                Episode_0 = self.decision_action.save_episode(action_value)
            else:
                action_value = exp_action[0]

            for x in exp_action:
                print("All exp action : {}".format(x))
            y_n = True
            return y_n, action_value, bp

        print("y/n:{}".format(y_n))

        if not bp:
            print("==========\nã“ã‚Œä»¥ä¸Šé€²ã‚ãªã„çŠ¶æ…‹\n or æ¬¡ã®ãƒã‚¹ã¯æ¢ç´¢æ¸ˆã¿\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
            self.lost = True
        else:
            self.All = True

        print("==========\nè¿·ã£ãŸçŠ¶æ…‹\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
        print("= ç¾åœ¨åœ°ã‹ã‚‰ã‚´ãƒ¼ãƒ«ã«è¿ãˆã‚‹é¸æŠè‚¢ã¯ãªã„\n")

    def mdp_exp(self, state, TRIGAR,     states_known, map, grid, DIR):
        self.TRIGAR_advance = TRIGAR
        
        # from mdp_virtual import ValueIterationPlanner
        from mdp_MP import ValueIterationPlanner

        
        test = ValueIterationPlanner(self.env)

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        self.trigar = TRIGAR
        self.All = False
        self.lost = False
        self.Reverse = False
        y_n = False
        bp = False
        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        # ä»Šã¯ã“ã“ã«å…¥ã£ã¦bp_algorithmã«é·ç§»ã—ã¦ã„ã‚‹
        if self.NODELIST[state.row][state.column] in pre:
                print("========\næ¢ç´¢çµ‚äº†\n========")
                self.trigar = False
                bp = True
        elif self.NODELIST[state.row][state.column] == "x":
            print("========\näº¤å·®ç‚¹\n========")
            self.trigar = False
        # else:
        #     self.trigar = None
        print("========\næ¢ç´¢é–‹å§‹\n========")
        exp_action = []
        for dir in next_diretion:
            # print("dir:{}".format(dir))
            y_n, action = self.env.expected_move(state, dir, self.trigar, self.All, self.marking_param)
            if y_n:
                y_n = False
                exp_action.append(action)
                # print("===== exp action : {} =====".format(exp_action))

        print("Unexplore:", exp_action)

        
        if exp_action:

            # print("Unexplore:", exp_action)

            if self.NODELIST[state.row][state.column] in pre or self.NODELIST[state.row][state.column] == "x": # here

                # import pprint
                # from env_virtual import State
                # size = 19 # 3
                # import copy
                # # pprint.pprint(states_known)
                # state_init = copy.copy(state)
                # # state_init = State(1, 1) # ä»®æƒ³åº§æ¨™
                # m = [[1.0 for i in range(size)] for i in range(size)] #known or unknown
                # for i in range(-1,2):
                #     if state_init.row+i < 0 or state_init.row+i >=size:
                #         continue
                #     for j in range(-1,2):
                #         if state_init.column+j < 0 or state_init.column+j >=size:
                #             continue
                        
                #         m[state_init.row+i][state_init.column+j] = 0
                # size = 19
                size = self.env.row_length
                m = [[1.0 for i in range(size)] for i in range(size)] #known or unknown
                for i in range(-1,2):
                    if state.row+i < 0 or state.row+i >=size:
                        continue
                    for j in range(-1,2):
                        if state.column+j < 0 or state.column+j >=size:
                            continue
                        
                        m[state.row+i][state.column+j] = 0
                states_known = set() #empty set
                for s in self.env.states:
                        if m[s.row][s.column] == 0:
                            states_known.add(s)

                # ns1 = copy.copy(state_init) # state.self.St.clone
                # ns2 = copy.copy(state_init) # state.self.St.clone
                # ns3 = copy.copy(state_init) # state.self.St.clone
                # ns4 = copy.copy(state_init) # state.self.St.clone
                # "å‰å¾Œå·¦å³ã®ãƒã‚¹ -> ä»Šã¯å¯è¦–åŒ–ã®ãŸã‚ã«åº§æ¨™ç³»ã‚’å‡ºã—ã¦ã„ã‚‹ãŒstate=(0, 0)"
                # states_known2 = set()
                # states_known2.add(state_init)
                # ns1.row -= 1
                # states_known2.add(ns1)
                # ns2.row += 1
                # states_known2.add(ns2)
                # ns3.column -= 1
                # states_known2.add(ns3)
                # ns4.column += 1
                # states_known2.add(ns4)

                # states_known2.add(State(0, 2))
                # states_known2.add(State(2, 2))
                # states_known2.add(State(0, 0))
                # states_known2.add(State(2, 0))

                # states_known2 = set()
                # states_known2.add(State(0, 0))
                # ns1.row -= 1
                # states_known2.add(ns1)
                # states_known2.add(State(0, 2))
                # ns3.column -= 1
                # states_known2.add(ns3)
                # states_known2.add(state_init)
                # ns4.column += 1
                # states_known2.add(ns4)
                # states_known2.add(State(2, 0))
                # ns2.row += 1
                # states_known2.add(ns2)
                # states_known2.add(State(2, 2))
                # print("----- states known 2 -----")
                # pprint.pprint(states_known2)

                
                
                # print("Unexplore:", exp_action)
                # if not exp_action:
                #     self.TRIGAR_advance = True
                #     exp_action = next_diretion # å…¨æ–¹å‘æ¢ç´¢ã—ãŸå ´åˆã¯é¸æŠæ–¹å‘ã‚’åˆæœŸåŒ–ã™ã‚‹

                # a, v, aaa = test.plan(states_known, map, state, DIR, exp_action) # here
                a, v, aaa = test.plan(states_known, m, state, DIR, exp_action) # here

                # a, v, aaa = test.plan(states_known2, m, state_init, DIR,     exp_action)
                
                new_pi = (aaa[state]) # here
                
                # new_pi = (aaa[state_init])

                
                print("===== NEW PI =====\n", new_pi)
                action = new_pi
                # test.show(aaa, v, state_init, m, DIR)
                test.show(aaa, v, state, m, DIR)
                test.show_values(a)

                
                # self.env.mark(state, None)

                
            else:
                "é€²ã‚ã‚‹æ–¹å‘ã«ç¶™ç¶šã—ã¦é€²ã‚€"
                action = exp_action[0]
            
            return action, bp, self.All, self.trigar, self.Reverse, self.lost
            

        if not bp:
            print("==========\nã“ã‚Œä»¥ä¸Šé€²ã‚ãªã„çŠ¶æ…‹\n or æ¬¡ã®ãƒã‚¹ã¯æ¢ç´¢æ¸ˆã¿\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
            self.lost = True
        else:
            self.All = True

        print("==========\nè¿·ã£ãŸçŠ¶æ…‹\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
        print("= ç¾åœ¨åœ°ã‹ã‚‰ã‚´ãƒ¼ãƒ«ã«è¿ãˆã‚‹é¸æŠè‚¢ã¯ãªã„\n")

        return action, bp, self.All, self.trigar, self.Reverse, self.lost








    def model_advance(self, state):

        next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]

        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()
        if self.NODELIST[state.row][state.column] in pre:
            print("ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®š")
            next_diretion = self.advance_direction_decision(next_diretion)
        else:
            next_diretion = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        # advanceã®è¡Œå‹•ã®å„ªå…ˆåº¦ã‚’ã‚ã‚‰ã‹ã˜ã‚è¨­å®š

        if self.NODELIST[state.row][state.column] == "x":
            print("ãƒ©ãƒ³ãƒ€ãƒ ã«æ±ºå®š")
            next_diretion = self.advance_direction_decision(next_diretion)
        print("next dir : {}".format(next_diretion))

        y_n = False
        self.All = False
        self.Reverse = False

        if self.NODELIST[state.row][state.column] == "x":
            print("========\näº¤å·®ç‚¹\n========")
            self.TRIGAR_advance = False

        print("========\nAdvanceé–‹å§‹\n========")
        if not self.TRIGAR_advance:
            for dir in next_diretion:

                print("dir:{}".format(dir))
                y_n, action = self.env.expected_move(state, dir, self.TRIGAR_advance, self.All, self.marking_param)

                if y_n:
                    self.prev_action = action
                    return action
                print("y/n:{}".format(y_n))
        print("==========\nè¿·ã£ãŸã€è¨±å®¹ã‚’è¶…ãˆã‚‹ã€‘çŠ¶æ…‹\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
        print("= ã“ã‚Œä»¥ä¸Šå…ˆã«ç¾åœ¨åœ°ã‹ã‚‰ã‚´ãƒ¼ãƒ«ã«è¿ãˆã‚‹é¸æŠè‚¢ã¯ãªã„\n= ä¸€æ—¦ä½“åˆ¶ã‚’æ•´ãˆã‚‹\n= æˆ»ã‚‹")
        print("\n ã¨ã„ã†ã‚ˆã‚Šã¯ã‚¹ãƒˆãƒ¬ã‚¹ãŒæºœã¾ã‚Šåˆ‡ã‚‹å‰ã«ã“ã‚Œä»¥ä¸Šé€²ã‚ãªããªã£ã¦ã‚¨ãƒ©ãƒ¼ãŒå‡ºã‚‹")
        self.TRIGAR_advance = True

    def model_bp(self, state):

        pre, Node, Arc, Arc_sum, PERMISSION = self.refer.reference()

        print("========\nBACK é–‹å§‹\n========")
        print("TRIGAR : {}".format(self.TRIGAR_bp))
        print("REVERSE : {}".format(self.TRIGAR_REVERSE_bp))
        
        if self.TRIGAR_REVERSE_bp:
            self.Reverse = True
            next_diretion = self.next_direction_decision("reverse")
            for dir in next_diretion:
                print("\ndir:{}".format(dir))
                y_n, action = self.env.expected_move_return_reverse(state, dir, self.TRIGAR_REVERSE_bp, self.Reverse)

                if y_n:
                    self.lost = False
                    return action, self.Reverse
                print("y/n:{}".format(y_n))
            print("TRIGAR REVERSE âš¡ï¸ğŸ")

        if self.TRIGAR_bp:
            next_diretion = self.next_direction_decision("trigar")

            for dir in next_diretion:
                print("\ndir:{}".format(dir))
                y_n, action = self.env.expected_move_return(state, dir, self.TRIGAR_bp, self.All)

                if y_n:
                    self.lost = False
                    return action, self.Reverse
                print("y/n:{}".format(y_n))

            if self.lost:
                print("==========\nã“ã‚Œä»¥ä¸Šæˆ»ã‚Œãªã„çŠ¶æ…‹\n or æ¬¡ã®ãƒã‚¹ã¯ä»¥å‰æˆ»ã£ãŸå ´æ‰€\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
                for dir in next_diretion:
                    print("\ndir:{}".format(dir))
                    y_n, action = self.env.expected_not_move(state, dir, self.trigar, self.All)

                    if y_n:
                        return action, self.Reverse
                    print("y/n:{}".format(y_n))

        print("==========\næˆ»ã‚Šçµ‚ã‚ã£ãŸçŠ¶æ…‹\n==========") # ã©ã®é¸æŠè‚¢ã‚‚ y_n = False
        print("= ç¾åœ¨åœ°ã‹ã‚‰æ¬¡ã«ã‚´ãƒ¼ãƒ«ã«è¿ãˆã‚‹é¸æŠè‚¢ã‚’é¸ã¶ã€æœªæ¢ç´¢æ–¹å‘ã€‘\n")
        self.lost = True

    # def back_position(self, BPLIST, w, Arc, Cost, Attribute): # change
    def back_position(self, test_bp_st, Attribute): # change

        print(f"BPLIST:{test_bp_st}")
        print("===== Attribute back_position =====")
        print(Attribute)
        # print(Attribute["weight"])]
        print(Attribute["stress"])
        print(Attribute["move cost"])
        print("===== Attribute back_position =====")
        # Attribute["WEIGHT CROSS"] = Attribute["weight"]*Attribute["move cost"] # here
        Attribute["PRODUCT"] = Attribute["stress"]*Attribute["move cost"]
        print(Attribute)
        print("===== Attribute min =====")
        "æ–°ã—ãåˆ—ã‚’è¿½åŠ ã™ã‚‹ver."
        # print(Attribute["WEIGHT CROSS"].min())
        # next_lm_index = Attribute["WEIGHT CROSS"].idxmin()
        print(Attribute["PRODUCT"].min())
        next_lm_index = Attribute["PRODUCT"].idxmin()
        print(next_lm_index)




        
        print("===== è¤‡æ•°å€‹ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’å–å¾—ã—ãŸéš›ã®å‡¦ç† =====")
        # # min_Index = Attribute["WEIGHT CROSS"][Attribute["WEIGHT CROSS"] == Attribute["WEIGHT CROSS"].min()].index
        # # min_Index = list(Attribute["WEIGHT CROSS"][Attribute["WEIGHT CROSS"] == Attribute["WEIGHT CROSS"].min()].index)
        # min_Index = Attribute["WEIGHT CROSS"][Attribute["WEIGHT CROSS"] == Attribute["WEIGHT CROSS"].min()].index.values
        min_Index = Attribute["PRODUCT"][Attribute["PRODUCT"] == Attribute["PRODUCT"].min()].index.values
        print(min_Index)

        min_cost = Attribute["move cost"].idxmin()
        print("min cost :", min_cost)
        
        # x = [x for x in min_Index if x == min_cost]
        # print("min Index == min cost :", x[0])
        
        if len(min_Index) > 1:
            print("min Index ãŒè¤‡æ•°å€‹ã‚ã‚Šã¾ã™ã€‚")
            print("min Index :", next_lm_index)
            "random ver."
            # min_Index = [random.choice(min_Index)] # ä»Šã¯ãƒ©ãƒ³ãƒ€ãƒ ã ãŒ move cost ãŒå°ã•ã„æ–¹ã«ã™ã‚‹
            "min cost ver."
            min_Index = [x for x in min_Index if x == min_cost]
            print("move cost ã®å°ã•ã„ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’é¸æŠ ... min Index == min cost :", min_Index)
            next_lm_index = min_Index[0]
            print(next_lm_index)

        "-------------------------------------------"
        "0129 -> Move Cost ãŒã‚¢ãƒ«ãƒ•ã‚¡ãƒ™ãƒƒãƒˆé †ã«ãªã‚‹ã®ã§ã€wã‚‚ãã†ã—ãªã„ã¨ã„ã‘ãªã„"
        "ã¤ã¾ã‚Šã€min(ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹)ã§ã¯ãƒ€ãƒ¡" # here ã®å ´æ‰€
        " + sãŒãªã„ã¨move_stepãŒä½™åˆ†ã«ã‚«ã‚¦ãƒ³ãƒˆã•ã‚Œã¦ã—ã¾ã†, ç§»å‹•ã‚³ã‚¹ãƒˆã¯sã‚ã‚Šãã§è€ƒãˆã¦ã„ã‚‹ã®ã§sã¯å¿…è¦"
        "-------------------------------------------"

        print("===== BPLIST[Attribute] =====")
        # print(BPLIST[Attribute])
        # next_position = BPLIST[Attribute]

        # "æ–°ã—ãåˆ—ã‚’è¿½åŠ ã™ã‚‹ver."
        # print(test_bp_st[next_lm_index])
        # # next_position = BPLIST[next] # here


        "æ–°ã—ãSTATEã‚’è¿½åŠ ã—ãŸAttribute ver."
        Attribute["STATE"] = test_bp_st
        print("===== TEST ATTRIBUTE =====")
        print(Attribute)
        print("-----")
        print(Attribute["STATE"][next_lm_index])
        # print(Attribute[next_lm_index]["STATE"])
        # next_position = Attribute["STATE"][next_lm_index]

        print(f"test----- \n{Attribute.loc[next_lm_index:next_lm_index]} -----")
        next_attribute = Attribute.loc[next_lm_index:next_lm_index]

        # return next_position, next_attribute
        return next_attribute

    # def back_end(self, BPLIST, next_position, w, OBS, test_index, move_cost_result, Attribute, next_attribute):
    def back_end(self, Attribute, next_attribute):

        print("===== Attribute(agent.py) =====")
        print(next_attribute.index)
        print(next_attribute.index[0])
        LM = next_attribute.index[0]

        "æˆ»ã£ãŸNode = NaNã«ã™ã‚‹"
        Attribute.loc[LM:LM] = np.nan # here ã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆã—ã¦ã‚‚retryã™ã‚‹æ™‚ã¯åˆæœŸåŒ–ã™ã‚‹ã®ã§æ„å‘³ãªã„

        print("===== Attribute(agent.py) =====")
        print(Attribute)

        # return BPLIST, w, OBS, Attribute
        return Attribute

    def next_direction_decision(self, trigar__or__reverse):
        if self.Advance_action == self.actions[0]: # Action.UP:
            self.BP_action = self.actions[1] # [0]
            next_diretion_trigar = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        elif self.Advance_action == self.actions[1]: # Action.DOWN:
            self.BP_action = self.actions[0] # [1]
            next_diretion_trigar = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
        elif self.Advance_action == self.actions[2]: # Action.LEFT:
            self.BP_action = self.actions[3] # [2]
            next_diretion_trigar = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
        elif self.Advance_action == self.actions[3]: # Action.RIGHT:
            self.BP_action = self.actions[2] # [3]
            next_diretion_trigar = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
        else:
            next_diretion_trigar, next_diretion_trigar_reverse = self.next_direction_decision_prev_action()

        if trigar__or__reverse == "trigar":
            print("tigar__or__reverse : {}".format(trigar__or__reverse))
            return next_diretion_trigar
        if trigar__or__reverse == "reverse":
            print("tigar__or__reverse : {}".format(trigar__or__reverse))
            return next_diretion_trigar_reverse

    def next_direction_decision_prev_action(self):
        if self.prev_action == self.actions[0]: # Action.UP:
            self.BP_action = self.actions[1]
            next_diretion_trigar = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
        elif self.prev_action == self.actions[1]: # Action.DOWN:
            self.BP_action = self.actions[0]
            next_diretion_trigar = [(self.actions[0]), (self.actions[1]), (self.actions[2]), (self.actions[3])]
            next_diretion_trigar_reverse = [(self.actions[1]), (self.actions[0]), (self.actions[2]), (self.actions[3])]
        elif self.prev_action == self.actions[2]: # Action.LEFT:
            self.BP_action = self.actions[3]
            next_diretion_trigar = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
        elif self.prev_action == self.actions[3]: # Action.RIGHT:
            self.BP_action = self.actions[2]
            next_diretion_trigar = [(self.actions[2]), (self.actions[3]), (self.actions[0]), (self.actions[1])]
            next_diretion_trigar_reverse = [(self.actions[3]), (self.actions[2]), (self.actions[0]), (self.actions[1])]

        return next_diretion_trigar, next_diretion_trigar_reverse

    def advance_direction_decision(self, dir):

        test = random.sample(dir, len(dir))
        print("test dir : {}, dir : {}".format(test, dir))
        return test # random.shuffle(dir)
        #  [<Action.RIGHT: -2>, <Action.DOWN: -1>, <Action.UP: 1>, <Action.LEFT: 2>]